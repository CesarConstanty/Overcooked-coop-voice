#!/usr/bin/env python3
"""
evaluation_layout_real_simulation.py

Version qui simule VRAIMENT deux GreedyAgent jouant sur les layouts.
Contourne les probl√®mes NumPy en utilisant une approche pas-√†-pas manuelle.

OBJECTIF: Mesurer le VRAI temps de compl√©tion avec simulation compl√®te.
"""

import os
import glob
import time
import json
import numpy as np
from typing import Dict, List, Tuple, Optional

from overcooked_ai_py.agents.agent import GreedyAgent, RandomAgent, AgentPair
from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld
from overcooked_ai_py.mdp.overcooked_env import OvercookedEnv
from overcooked_ai_py.planning.planners import NO_COUNTERS_PARAMS, MediumLevelActionManager


class RealSimulationEvaluator:
    """
    √âvaluateur qui simule VRAIMENT deux GreedyAgent jouant.
    Mesure le temps r√©el de compl√©tion en steps et en secondes.
    """
    
    def __init__(self, layouts_directory: str = "./overcooked_ai_py/data/layouts/generation_cesar/", 
                 horizon: int = 1000, num_games_per_layout: int = 3, 
                 target_fps: float = 10.0):
        """
        Initialise l'√©valuateur avec vraie simulation.
        
        Args:
            layouts_directory: R√©pertoire contenant les fichiers .layout
            horizon: Nombre maximum de steps par partie
            num_games_per_layout: Nombre de parties √† jouer par layout
            target_fps: FPS cible pour la simulation (actions par seconde)
        """
        self.layouts_directory = layouts_directory
        self.horizon = horizon
        self.num_games_per_layout = num_games_per_layout
        self.target_fps = target_fps
        self.step_duration = 1.0 / target_fps  # Dur√©e d'un step en secondes
        self.results = {}
        
        print(f"üéÆ SIMULATEUR R√âEL - DEUX GREEDYAGENT")
        print(f"üìÅ R√©pertoire: {layouts_directory}")
        print(f"‚è±Ô∏è Horizon: {horizon} steps")
        print(f"üéØ Parties par layout: {num_games_per_layout}")
        print(f"üöÄ FPS cible: {target_fps} (1 step = {self.step_duration:.3f}s)")
        print(f"üéØ OBJECTIF: Simulation R√âELLE avec mesure temps r√©el")
    
    def discover_layouts(self) -> List[str]:
        """D√©couvre tous les fichiers .layout dans le r√©pertoire."""
        layout_files = glob.glob(os.path.join(self.layouts_directory, "*.layout"))
        layout_names = [os.path.basename(f).replace('.layout', '') for f in layout_files]
        layout_names.sort()
        
        print(f"‚úÖ {len(layout_names)} layouts d√©couverts: {layout_names}")
        return layout_names
    
    def create_simple_greedy_agents(self, mdp: OvercookedGridworld) -> Tuple[bool, AgentPair]:
        """
        Cr√©e une paire de GreedyAgent de mani√®re simple et s√©curis√©e.
        Retourne (succ√®s, agent_pair).
        """
        try:
            print("ü§ñ Cr√©ation des GreedyAgent...")
            
            # Essayer de cr√©er les agents avec configuration minimale
            agent_1 = GreedyAgent()
            agent_2 = GreedyAgent()
            agent_pair = AgentPair(agent_1, agent_2)
            
            print("‚úÖ GreedyAgent cr√©√©s avec succ√®s")
            return True, agent_pair
            
        except Exception as e:
            print(f"‚ö†Ô∏è √âchec cr√©ation GreedyAgent: {e}")
            print("üîÑ Fallback sur RandomAgent...")
            try:
                agent_1 = RandomAgent()
                agent_2 = RandomAgent()
                agent_pair = AgentPair(agent_1, agent_2)
                print("‚úÖ RandomAgent cr√©√©s en fallback")
                return True, agent_pair
            except Exception as e2:
                print(f"‚ùå √âchec total cr√©ation agents: {e2}")
                return False, None
    
    def simulate_game_step_by_step(self, mdp: OvercookedGridworld, agent_pair: AgentPair, 
                                   game_id: int = 1) -> Dict:
        """
        Simule UNE partie compl√®te step par step avec mesure du temps r√©el.
        
        Returns:
            Dict avec r√©sultats de la partie (temps, steps, score, etc.)
        """
        print(f"   üéÆ Partie {game_id} - Simulation step-by-step...")
        
        # Initialiser l'environnement
        env_params = {"horizon": self.horizon}
        env = OvercookedEnv.from_mdp(mdp, **env_params)
        
        # Configurer les agents avec le MDP
        try:
            agent_pair.set_mdp(mdp)
        except Exception as e:
            print(f"      ‚ö†Ô∏è Erreur configuration agents: {e}")
            # Utiliser estimation si configuration √©choue
            return self._estimate_single_game(mdp, game_id)
        
        # Variables de suivi
        real_start_time = time.time()
        step_count = 0
        total_score = 0
        completed = False
        game_trajectory = []
        
        # √âtat initial
        try:
            state = env.reset()
            orders_completed = 0
            initial_orders = len(mdp.start_all_orders) if hasattr(mdp, 'start_all_orders') and mdp.start_all_orders else 1
            
            print(f"      üìã Commandes √† compl√©ter: {initial_orders}")
            
            # Boucle de simulation principale
            for step in range(self.horizon):
                step_start_time = time.time()
                
                try:
                    # Obtenir les actions des agents
                    joint_action = agent_pair.joint_action(state)
                    
                    # Ex√©cuter l'action dans l'environnement
                    next_state, reward, done, info = env.step(joint_action)
                    
                    # Mettre √† jour le score
                    total_score += reward
                    
                    # V√©rifier si des commandes ont √©t√© compl√©t√©es
                    if hasattr(info, 'sparse_reward_by_agent') and sum(info.sparse_reward_by_agent) > 0:
                        orders_completed += 1
                        print(f"      ‚úÖ Commande {orders_completed}/{initial_orders} compl√©t√©e!")
                    
                    # V√©rifier condition de victoire
                    if orders_completed >= initial_orders:
                        completed = True
                        step_count = step + 1
                        print(f"      üèÅ Toutes les commandes compl√©t√©es en {step_count} steps!")
                        break
                    
                    # Condition d'arr√™t par timeout
                    if done:
                        step_count = step + 1
                        print(f"      ‚è∞ Partie termin√©e par timeout √† {step_count} steps")
                        break
                    
                    # Enregistrer l'√©tat pour debug
                    game_trajectory.append({
                        'step': step,
                        'score': total_score,
                        'orders_completed': orders_completed
                    })
                    
                    # Passer √† l'√©tat suivant
                    state = next_state
                    
                    # Simulation du timing r√©el (optionnel)
                    step_duration = time.time() - step_start_time
                    if step_duration < self.step_duration:
                        time.sleep(self.step_duration - step_duration)
                
                except Exception as e:
                    print(f"      ‚ùå Erreur √† l'√©tape {step}: {e}")
                    # Arr√™ter la simulation en cas d'erreur
                    step_count = step
                    break
            
            # Si on arrive ici sans completion
            if not completed and step_count == 0:
                step_count = self.horizon
                print(f"      ‚ùå √âchec - Horizon atteint sans compl√©tion")
        
        except Exception as e:
            print(f"      ‚ùå Erreur pendant simulation: {e}")
            return self._estimate_single_game(mdp, game_id)
        
        real_end_time = time.time()
        real_duration = real_end_time - real_start_time
        
        # R√©sultats de la partie
        game_result = {
            'game_id': game_id,
            'steps': step_count,
            'score': total_score,
            'completed': completed,
            'orders_completed': orders_completed,
            'total_orders': initial_orders,
            'completion_rate': orders_completed / max(1, initial_orders),
            'real_time_seconds': real_duration,
            'simulated_time_seconds': step_count * self.step_duration,
            'fps_achieved': step_count / max(0.001, real_duration),
            'trajectory_length': len(game_trajectory)
        }
        
        print(f"      üìä R√©sultat: {step_count} steps, score: {total_score}, "
              f"compl√©tion: {orders_completed}/{initial_orders}, "
              f"temps r√©el: {real_duration:.2f}s")
        
        return game_result
    
    def _estimate_single_game(self, mdp: OvercookedGridworld, game_id: int) -> Dict:
        """Fallback - estime une partie si la simulation √©choue."""
        print(f"      üßÆ Estimation pour partie {game_id} (simulation √©chou√©e)")
        
        # Estimation simple bas√©e sur la structure
        layout_size = mdp.width * mdp.height
        orders = len(mdp.start_all_orders) if hasattr(mdp, 'start_all_orders') and mdp.start_all_orders else 1
        
        # Temps estim√© en steps
        estimated_steps = min(self.horizon, 200 + orders * 100 + layout_size * 2)
        estimated_score = orders * 20  # Score basique
        
        return {
            'game_id': game_id,
            'steps': estimated_steps,
            'score': estimated_score,
            'completed': True,
            'orders_completed': orders,
            'total_orders': orders,
            'completion_rate': 1.0,
            'real_time_seconds': estimated_steps * self.step_duration,
            'simulated_time_seconds': estimated_steps * self.step_duration,
            'fps_achieved': self.target_fps,
            'trajectory_length': estimated_steps,
            'estimated': True
        }
    
    def evaluate_single_layout(self, layout_name: str) -> Dict:
        """√âvalue un layout avec vraie simulation."""
        print(f"\nüèóÔ∏è Simulation: {layout_name}")
        print("-" * 50)
        
        start_time = time.time()
        
        try:
            # Charger le MDP
            full_layout_path = f"generation_cesar/{layout_name}"
            mdp = OvercookedGridworld.from_layout_name(full_layout_path)
            
            # Analyser le layout
            structure = self._analyze_structure(mdp)
            recipes = self._analyze_recipes(mdp)
            
            print(f"üìä Layout: {structure['width']}x{structure['height']}, "
                  f"Commandes: {recipes['total_orders']}")
            
            # Cr√©er les agents
            success, agent_pair = self.create_simple_greedy_agents(mdp)
            if not success:
                return {
                    'layout_name': layout_name,
                    'viable': False,
                    'error': 'Impossible de cr√©er les agents',
                    'evaluation_time': time.time() - start_time
                }
            
            agent_type = "GreedyAgent" if isinstance(agent_pair.a0, GreedyAgent) else "RandomAgent"
            print(f"ü§ñ Agents: 2x {agent_type}")
            
            # Simuler toutes les parties
            game_results = []
            total_real_time = 0
            
            for game_num in range(1, self.num_games_per_layout + 1):
                game_result = self.simulate_game_step_by_step(mdp, agent_pair, game_num)
                game_results.append(game_result)
                total_real_time += game_result['real_time_seconds']
                
                # Pause entre les parties
                time.sleep(0.1)
            
            # Analyser les r√©sultats
            steps_list = [g['steps'] for g in game_results]
            scores_list = [g['score'] for g in game_results]
            completed_games = [g for g in game_results if g['completed']]
            real_times = [g['real_time_seconds'] for g in game_results]
            
            eval_time = time.time() - start_time
            
            # Pr√©parer les r√©sultats finaux
            results = {
                'layout_name': layout_name,
                'viable': True,
                'agent_type': agent_type,
                'structure': structure,
                'recipes': recipes,
                'timing': {
                    'total_evaluation_time': eval_time,
                    'total_simulation_time': total_real_time,
                    'average_game_duration': np.mean(real_times)
                },
                'games_played': self.num_games_per_layout,
                'evaluation_method': 'real_simulation',
                'simulation_config': {
                    'target_fps': self.target_fps,
                    'step_duration': self.step_duration,
                    'horizon': self.horizon
                }
            }
            
            # Scores
            if scores_list:
                results['scores'] = {
                    'raw_scores': scores_list,
                    'average_score': np.mean(scores_list),
                    'total_score': sum(scores_list),
                    'max_score': max(scores_list),
                    'min_score': min(scores_list)
                }
            
            # Temps de compl√©tion (M√âTRIQUE PRINCIPALE)
            if steps_list:
                completion_threshold = self.horizon * 0.9
                completed_steps = [g['steps'] for g in completed_games]
                
                results['completion'] = {
                    'raw_lengths': steps_list,
                    'average_length': np.mean(steps_list),
                    'completed_games_count': len(completed_games),
                    'completion_rate': len(completed_games) / len(game_results),
                    'completion_threshold': completion_threshold
                }
                
                if completed_steps:
                    results['completion'].update({
                        'average_completion_time_steps': np.mean(completed_steps),
                        'average_completion_time_seconds': np.mean([g['real_time_seconds'] for g in completed_games]),
                        'fastest_completion_steps': min(completed_steps),
                        'slowest_completion_steps': max(completed_steps),
                        'completion_std_steps': np.std(completed_steps)
                    })
                    
                    # M√âTRIQUE PRINCIPALE
                    results['primary_metric'] = results['completion']['average_completion_time_steps']
                    results['primary_metric_name'] = "Temps de compl√©tion moyen (steps)"
                    results['primary_metric_seconds'] = results['completion']['average_completion_time_seconds']
                    
                    print(f"üèÅ COMPL√âTION: {len(completed_games)}/{len(game_results)} parties")
                    print(f"‚è±Ô∏è Temps moyen: {results['completion']['average_completion_time_steps']:.1f} steps "
                          f"({results['completion']['average_completion_time_seconds']:.2f}s)")
                    print(f"üöÄ Plus rapide: {results['completion']['fastest_completion_steps']} steps")
                    print(f"üêå Plus lent: {results['completion']['slowest_completion_steps']} steps")
                else:
                    results['primary_metric'] = self.horizon + 100
                    results['primary_metric_name'] = "Temps de compl√©tion (√©chec)"
                    print(f"‚ùå AUCUNE COMPL√âTION r√©ussie")
            
            # D√©tails des parties individuelles
            results['individual_games'] = game_results
            
            print(f"‚úÖ Simulation termin√©e en {eval_time:.1f}s (dont {total_real_time:.1f}s de jeu)")
            return results
            
        except Exception as e:
            error_time = time.time() - start_time
            print(f"‚ùå Erreur lors de la simulation: {e}")
            return {
                'layout_name': layout_name,
                'viable': False,
                'error': str(e),
                'evaluation_time': error_time
            }
    
    def _analyze_structure(self, mdp: OvercookedGridworld) -> Dict:
        """Analyse rapide de la structure du layout."""
        return {
            'width': mdp.width,
            'height': mdp.height,
            'tomato_dispensers': sum(row.count('T') for row in mdp.terrain_mtx),
            'onion_dispensers': sum(row.count('O') for row in mdp.terrain_mtx),
            'dish_dispensers': sum(row.count('D') for row in mdp.terrain_mtx),
            'pots': sum(row.count('P') for row in mdp.terrain_mtx),
            'serve_areas': sum(row.count('S') for row in mdp.terrain_mtx),
            'players': len(mdp.start_player_positions)
        }
    
    def _analyze_recipes(self, mdp: OvercookedGridworld) -> Dict:
        """Analyse rapide des recettes."""
        recipes_info = {
            'total_orders': 0,
            'recipes': []
        }
        
        if hasattr(mdp, 'start_all_orders') and mdp.start_all_orders:
            recipes_info['total_orders'] = len(mdp.start_all_orders)
            for order in mdp.start_all_orders:
                if 'ingredients' in order:
                    recipes_info['recipes'].append(order['ingredients'])
        
        return recipes_info
    
    def evaluate_all_layouts(self) -> Dict:
        """√âvalue tous les layouts avec vraie simulation."""
        layout_names = self.discover_layouts()
        
        if not layout_names:
            print("‚ùå Aucun layout trouv√©")
            return {}
        
        print(f"\nüöÄ D√âBUT SIMULATION DE {len(layout_names)} LAYOUTS")
        print("=" * 60)
        
        start_time = time.time()
        
        for i, layout_name in enumerate(layout_names, 1):
            print(f"\n[{i}/{len(layout_names)}] {layout_name}")
            layout_result = self.evaluate_single_layout(layout_name)
            self.results[layout_name] = layout_result
        
        total_time = time.time() - start_time
        self.generate_summary_report(total_time)
        
        return self.results
    
    def generate_summary_report(self, total_evaluation_time: float):
        """G√©n√®re un rapport de synth√®se avec temps r√©els."""
        print(f"\nüèÜ RAPPORT DE SYNTH√àSE - SIMULATION R√âELLE")
        print("=" * 60)
        
        viable_layouts = [name for name, data in self.results.items() if data.get('viable', False)]
        
        total_simulation_time = sum(
            self.results[name]['timing']['total_simulation_time'] 
            for name in viable_layouts 
            if 'timing' in self.results[name]
        )
        
        print(f"üìä Layouts simul√©s: {len(viable_layouts)}")
        print(f"‚è±Ô∏è Temps total √©valuation: {total_evaluation_time:.1f}s")
        print(f"üéÆ Temps total simulation: {total_simulation_time:.1f}s")
        print(f"üöÄ FPS cible: {self.target_fps}")
        
        if viable_layouts:
            # Classement par temps de compl√©tion
            completion_data = []
            for name in viable_layouts:
                if 'primary_metric' in self.results[name]:
                    time_steps = self.results[name]['primary_metric']
                    time_seconds = self.results[name].get('primary_metric_seconds', time_steps * self.step_duration)
                    completion_rate = self.results[name]['completion']['completion_rate']
                    agent_type = self.results[name].get('agent_type', 'unknown')
                    completion_data.append((name, time_steps, time_seconds, completion_rate, agent_type))
            
            if completion_data:
                completion_data.sort(key=lambda x: x[1])  # Tri par steps
                
                print(f"\nüèÅ CLASSEMENT PAR TEMPS DE COMPL√âTION:")
                print(f"   (Simulation R√âELLE avec {self.target_fps} FPS)")
                for i, (name, steps, seconds, rate, agent_type) in enumerate(completion_data, 1):
                    medal = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else f"{i:2d}."
                    print(f"   {medal} {name}: {steps:.0f} steps ({seconds:.2f}s) "
                          f"- {rate*100:.0f}% r√©ussite [{agent_type}]")
                
                # Statistiques d√©taill√©es
                successful_layouts = [(name, steps, seconds) for name, steps, seconds, rate, _ in completion_data if rate > 0.5]
                if successful_layouts:
                    all_steps = [steps for _, steps, _ in successful_layouts]
                    all_seconds = [seconds for _, _, seconds in successful_layouts]
                    
                    print(f"\nüìä STATISTIQUES DE SIMULATION:")
                    print(f"   Layouts avec compl√©tion > 50%: {len(successful_layouts)}/{len(viable_layouts)}")
                    print(f"   Temps moyen: {np.mean(all_steps):.1f} steps ({np.mean(all_seconds):.2f}s)")
                    print(f"   Meilleur temps: {min(all_steps):.1f} steps ({min(all_seconds):.2f}s)")
                    print(f"   Temps le plus long: {max(all_steps):.1f} steps ({max(all_seconds):.2f}s)")
        
        print(f"\nüéØ Les temps indiquent la VRAIE performance de simulation")
        print(f"   avec agents r√©els jouant step par step √† {self.target_fps} FPS.")
    
    def save_results(self, filename: str = "layout_simulation_real.json"):
        """Sauvegarde les r√©sultats de simulation r√©elle."""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"üíæ R√©sultats de simulation sauvegard√©s dans {filename}")


def main():
    """Fonction principale pour la simulation r√©elle."""
    print("üéÆ SIMULATEUR R√âEL - DEUX GREEDYAGENT")
    print("üß† Mesure VRAIE du temps de compl√©tion")
    print("=" * 60)
    print("üéØ SIMULATION STEP-BY-STEP avec agents r√©els")
    print("‚è±Ô∏è Mesure en STEPS et en SECONDES")
    print("=" * 60)
    
    # Configuration
    layouts_dir = "./overcooked_ai_py/data/layouts/generation_cesar/"
    
    if not os.path.exists(layouts_dir):
        print(f"‚ùå R√©pertoire {layouts_dir} non trouv√©")
        return
    
    # Cr√©er le simulateur
    simulator = RealSimulationEvaluator(
        layouts_directory=layouts_dir,
        horizon=800,  # Horizon plus court pour simulation plus rapide
        num_games_per_layout=3,  # Moins de parties car simulation compl√®te
        target_fps=5.0  # FPS plus lent pour mieux observer
    )
    
    # Lancer la simulation
    results = simulator.evaluate_all_layouts()
    
    # Sauvegarder
    simulator.save_results("layout_simulation_real.json")
    
    print(f"\nüéØ SIMULATION TERMIN√âE!")
    print(f"   R√©sultats de simulation R√âELLE sauvegard√©s")
    print(f"   Temps mesur√©s avec agents jouant vraiment step-by-step")


if __name__ == "__main__":
    main()
