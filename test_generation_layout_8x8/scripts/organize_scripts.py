#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Nettoyage et organisation des scripts - Un script par √©tape
Objectif : Production et √©valuation en masse de layouts
"""

import shutil
from pathlib import Path

class ScriptsCleaner:
    """Nettoyeur et organisateur des scripts."""
    
    def __init__(self):
        """Initialise le nettoyeur."""
        self.base_dir = Path(__file__).parent.parent
        self.scripts_dir = self.base_dir / "scripts"
        
        print(f"üßπ Organisation des scripts dans: {self.scripts_dir}")
    
    def analyze_current_scripts(self):
        """Analyse les scripts actuels."""
        print(f"\nüìä ANALYSE DES SCRIPTS ACTUELS")
        print("="*60)
        
        scripts = list(self.scripts_dir.glob("*.py"))
        scripts = [s for s in scripts if not s.name.startswith("__")]
        
        # Grouper par √©tape
        by_step = {
            "0_generation_recettes": [],
            "1_generation_layouts": [],
            "3_evaluation": [],
            "4_selection_analyse": [],
            "utils": []
        }
        
        for script in scripts:
            name = script.name
            if name.startswith("0_"):
                by_step["0_generation_recettes"].append(script)
            elif name.startswith("1_"):
                by_step["1_generation_layouts"].append(script)
            elif name.startswith("3_"):
                by_step["3_evaluation"].append(script)
            elif name.startswith("4_"):
                by_step["4_selection_analyse"].append(script)
            else:
                by_step["utils"].append(script)
        
        for step, step_scripts in by_step.items():
            print(f"\nüìÅ {step.upper()}:")
            for script in step_scripts:
                size = script.stat().st_size / 1024
                print(f"   üìÑ {script.name} ({size:.1f} KB)")
        
        return by_step
    
    def define_final_pipeline(self):
        """D√©finit le pipeline final avec un script par √©tape."""
        print(f"\nüéØ PIPELINE FINAL RECOMMAND√â")
        print("="*60)
        
        final_pipeline = {
            "0_recipe_generator.py": {
                "source": "0_recipe_groups_generator.py",
                "description": "G√©n√©ration des groupes de recettes (sans doublons)",
                "action": "renommer"
            },
            "1_layout_generator.py": {
                "source": "1_validated_layout_generator.py", 
                "description": "G√©n√©ration massive de layouts valid√©s",
                "action": "renommer"
            },
            "2_layout_evaluator.py": {
                "source": "3_exhaustive_evaluator.py",
                "description": "√âvaluation exhaustive layouts √ó groupes de recettes",
                "action": "renommer"
            },
            "3_result_analyzer.py": {
                "source": "4_exhaustive_analyzer.py",
                "description": "Analyse des r√©sultats et s√©lection optimale",
                "action": "renommer"
            },
            "utils_cleanup.py": {
                "source": "cleanup_outputs.py",
                "description": "Nettoyage et organisation des outputs",
                "action": "renommer"
            }
        }
        
        print(f"üöÄ √âTAPES DU PIPELINE DE PRODUCTION:")
        for i, (final_name, info) in enumerate(final_pipeline.items(), 1):
            print(f"   {i}. {final_name}")
            print(f"      ‚Üê {info['source']}")
            print(f"      üìù {info['description']}")
        
        return final_pipeline
    
    def identify_scripts_to_remove(self, final_pipeline):
        """Identifie les scripts √† supprimer."""
        print(f"\nüóëÔ∏è  SCRIPTS √Ä SUPPRIMER")
        print("="*60)
        
        # Scripts √† conserver (sources du pipeline final)
        keep_sources = set(info["source"] for info in final_pipeline.values())
        keep_sources.add("verify_recipes.py")  # Utilitaire de v√©rification
        
        # Tous les scripts
        all_scripts = list(self.scripts_dir.glob("*.py"))
        all_scripts = [s for s in all_scripts if not s.name.startswith("__")]
        
        # Scripts √† supprimer
        to_remove = []
        for script in all_scripts:
            if script.name not in keep_sources and script.name != Path(__file__).name:
                to_remove.append(script)
        
        print(f"üìã SCRIPTS OBSOL√àTES:")
        total_size = 0
        for script in to_remove:
            size = script.stat().st_size
            total_size += size
            print(f"   üóëÔ∏è  {script.name} ({size/1024:.1f} KB)")
        
        print(f"\nüìä √âCONOMIE: {len(to_remove)} scripts, {total_size/1024:.1f} KB")
        
        return to_remove
    
    def reorganize_scripts(self, final_pipeline, to_remove, confirm=True):
        """R√©organise les scripts selon le pipeline final."""
        
        if confirm:
            print(f"\n‚ö†Ô∏è  ATTENTION: R√©organisation des scripts")
            print(f"   - {len(to_remove)} scripts seront supprim√©s")
            print(f"   - {len(final_pipeline)} scripts seront renomm√©s")
            response = input("Confirmer la r√©organisation ? (oui/non): ").lower().strip()
            if response not in ['oui', 'o', 'yes', 'y']:
                print("‚ùå R√©organisation annul√©e")
                return False
        
        print(f"\nüîÑ R√âORGANISATION EN COURS...")
        
        # 1. Supprimer les scripts obsol√®tes
        for script in to_remove:
            try:
                script.unlink()
                print(f"   üóëÔ∏è  Supprim√©: {script.name}")
            except Exception as e:
                print(f"   ‚ùå Erreur suppression {script.name}: {e}")
        
        # 2. Renommer selon le pipeline final
        for final_name, info in final_pipeline.items():
            source_path = self.scripts_dir / info["source"]
            final_path = self.scripts_dir / final_name
            
            if source_path.exists():
                try:
                    if final_path.exists():
                        final_path.unlink()  # Supprimer si existe d√©j√†
                    
                    source_path.rename(final_path)
                    print(f"   ‚úÖ {info['source']} ‚Üí {final_name}")
                except Exception as e:
                    print(f"   ‚ùå Erreur renommage {info['source']}: {e}")
            else:
                print(f"   ‚ö†Ô∏è  Source manquante: {info['source']}")
        
        return True
    
    def create_pipeline_documentation(self):
        """Cr√©e la documentation du pipeline."""
        print(f"\nüìö CR√âATION DE LA DOCUMENTATION")
        print("="*60)
        
        doc_content = '''# Pipeline de Production et √âvaluation de Layouts

## üéØ Objectif
Production et √©valuation en masse de layouts pour l'√©tude de coop√©ration humain-IA dans Overcooked.

## üöÄ Pipeline de Production

### √âtape 0: G√©n√©ration des Recettes
```bash
python3 scripts/0_recipe_generator.py --group-size 6
```
- G√©n√®re tous les groupes de 6 recettes diff√©rentes
- √âlimine les doublons fonctionnels
- Sortie: `outputs/all_recipe_groups_*.json`

### √âtape 1: G√©n√©ration des Layouts
```bash
python3 scripts/1_layout_generator.py --target-count 1000 --processes 4
```
- G√©n√®re des layouts 8x8 valid√©s avec connectivit√© compl√®te
- V√©rifie l'accessibilit√© de tous les objets
- Sortie: `outputs/validated_layouts/`

### √âtape 2: √âvaluation Exhaustive
```bash
python3 scripts/2_layout_evaluator.py --layout-sample 100 --processes 4
```
- √âvalue chaque layout avec chaque groupe de recettes
- Calcule les m√©triques de coop√©ration (efficiency, gain, exchanges)
- Sortie: `outputs/exhaustive_evaluation/`

### √âtape 3: Analyse et S√©lection
```bash
python3 scripts/3_result_analyzer.py outputs/exhaustive_evaluation/results.json
```
- Analyse les r√©sultats d'√©valuation
- Identifie les meilleures combinaisons layout-recettes
- G√©n√®re des rapports de performance

### Utilitaires

#### Nettoyage des Outputs
```bash
python3 scripts/utils_cleanup.py --auto-confirm
```
- Nettoie les fichiers obsol√®tes
- Organise la structure des dossiers

#### V√©rification des Recettes
```bash
python3 scripts/verify_recipes.py outputs/all_recipe_groups_*.json
```
- V√©rifie l'absence de doublons dans les recettes

## üìä Structure des Outputs

```
outputs/
‚îú‚îÄ‚îÄ validated_layouts/          # Layouts g√©n√©r√©s et valid√©s
‚îú‚îÄ‚îÄ exhaustive_evaluation/      # R√©sultats d'√©valuations
‚îú‚îÄ‚îÄ final_selection/           # S√©lection finale pour exp√©riences
‚îú‚îÄ‚îÄ all_recipe_groups_*.json   # Groupes de recettes
‚îî‚îÄ‚îÄ base_recipes_*.json        # Recettes de base
```

## üéÆ M√©triques de Coop√©ration

1. **Efficiency (duo_steps)**: Nombre d'√©tapes en mode coop√©ratif
2. **Cooperation Gain**: Pourcentage d'am√©lioration vs solo  
3. **Exchanges**: Nombre d'√©changes d'objets estim√©s

## üîß Configuration

Les param√®tres sont configurables via les arguments de ligne de commande :
- `--target-count`: Nombre de layouts √† g√©n√©rer
- `--processes`: Parall√©lisme (d√©faut: 4)
- `--layout-sample`: √âchantillon de layouts pour √©valuation
- `--recipe-group-sample`: √âchantillon de groupes de recettes

## üìà Performance

- G√©n√©ration: ~1000 layouts/minute
- √âvaluation: ~20,000 √©valuations/seconde  
- Pipeline complet: quelques minutes pour 1000 layouts √ó 924 groupes
'''
        
        readme_path = self.base_dir / "README_PIPELINE.md"
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(doc_content)
        
        print(f"‚úÖ Documentation cr√©√©e: README_PIPELINE.md")
    
    def show_final_structure(self):
        """Affiche la structure finale des scripts."""
        print(f"\nüéØ STRUCTURE FINALE DES SCRIPTS")
        print("="*60)
        
        scripts = sorted(self.scripts_dir.glob("*.py"))
        scripts = [s for s in scripts if not s.name.startswith("__")]
        
        pipeline_scripts = []
        utility_scripts = []
        
        for script in scripts:
            if script.name.startswith(('0_', '1_', '2_', '3_')):
                pipeline_scripts.append(script)
            else:
                utility_scripts.append(script)
        
        print(f"üöÄ SCRIPTS DU PIPELINE:")
        for script in pipeline_scripts:
            size = script.stat().st_size / 1024
            print(f"   üìÑ {script.name} ({size:.1f} KB)")
        
        print(f"\nüîß SCRIPTS UTILITAIRES:")
        for script in utility_scripts:
            size = script.stat().st_size / 1024
            print(f"   üìÑ {script.name} ({size:.1f} KB)")
        
        print(f"\nüìä TOTAL: {len(scripts)} scripts")

def main():
    """Fonction principale."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Organisation des scripts du pipeline")
    parser.add_argument("--analyze-only", action="store_true",
                       help="Analyser uniquement, sans r√©organiser")
    parser.add_argument("--auto-confirm", action="store_true",
                       help="R√©organiser automatiquement sans confirmation")
    
    args = parser.parse_args()
    
    try:
        cleaner = ScriptsCleaner()
        
        # Analyse
        cleaner.analyze_current_scripts()
        final_pipeline = cleaner.define_final_pipeline()
        to_remove = cleaner.identify_scripts_to_remove(final_pipeline)
        
        if args.analyze_only:
            print("\nüîç Analyse termin√©e (aucune modification)")
        else:
            # R√©organisation
            success = cleaner.reorganize_scripts(
                final_pipeline, to_remove, 
                confirm=not args.auto_confirm
            )
            
            if success:
                cleaner.create_pipeline_documentation()
                cleaner.show_final_structure()
                print("\n‚úÖ R√©organisation termin√©e!")
            else:
                print("\n‚ùå R√©organisation annul√©e")
        
    except Exception as e:
        print(f"üí• Erreur: {e}")
        import traceback
        traceback.print_exc()
        exit(1)

if __name__ == "__main__":
    main()
