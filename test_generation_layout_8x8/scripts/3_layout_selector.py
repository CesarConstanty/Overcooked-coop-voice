#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
S√©lecteur de Layouts Overcooked
S√©lectionne les meilleurs layouts bas√©s sur les m√©triques d'√©valuation et les convertit au format requis

Fonctionnalit√©s:
1. Charge les r√©sultats d'√©valuation de tous les batches
2. Calcule des scores pond√©r√©s pour chaque layout
3. S√©lectionne les N meilleurs layouts selon les crit√®res de configuration
4. Convertit au format .layout standard du projet Overcooked
5. Sauvegarde dans le dossier layouts_finaux

Crit√®res de s√©lection:
- B√©n√©fice de coop√©ration (solo_steps vs duo_steps)
- Efficacit√© (nombre d'√©tapes duo)
- Potentiel d'√©changes
- Diversit√© des layouts

Author: Assistant AI Expert
Date: Septembre 2025
"""

import json
import gzip
import base64
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from collections import defaultdict
import argparse
import logging

# Configuration du logging
logs_dir = Path(__file__).parent.parent / "logs"
logs_dir.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(logs_dir / 'layout_selection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class LayoutMetrics:
    """M√©triques simplifi√©es pour un layout - 3 m√©triques seulement"""
    layout_id: str
    layout_hash: str
    recipe_group_id: int
    solo_steps: int
    duo_steps: int
    exchanges_count: int
    recipe_hash: str
    
    def step_reduction_percentage(self) -> float:
        """Facteur 1: Pourcentage de gain en nombre d'√©tapes (duo vs solo)"""
        if self.solo_steps <= 0:
            return 0.0
        reduction = max(0, self.solo_steps - self.duo_steps)
        return (reduction / self.solo_steps) * 100.0  # Pourcentage de 0 √† 100
    
    def exchanges_count_raw(self) -> int:
        """Facteur 2: Nombre d'√©changes r√©alis√©s dans la version duo"""
        return self.exchanges_count
    
    def duo_steps_total(self) -> int:
        """Facteur 3: Nombre total d'√©tapes n√©cessaires en duo"""
        return self.duo_steps

@dataclass
class LayoutCandidate:
    """Candidat layout avec ses m√©triques agr√©g√©es"""
    layout_id: str
    layout_hash: str
    grid: List[List[str]]
    object_positions: Dict[str, Tuple[int, int]]
    metrics_by_recipe: Dict[int, LayoutMetrics]
    
    def calculate_weighted_score(self, weights: Dict[str, float]) -> float:
        """
        Calcule le score pond√©r√© simplifi√© bas√© sur 3 m√©triques uniquement:
        1. step_reduction_weight: Pourcentage de gain d'√©tapes (duo vs solo)
        2. exchanges_weight: Nombre d'√©changes r√©alis√©s en duo  
        3. duo_steps_weight: Nombre total d'√©tapes en duo (invers√© - moins c'est mieux)
        """
        if not self.metrics_by_recipe:
            return 0.0
        
        total_score = 0.0
        for metrics in self.metrics_by_recipe.values():
            # Facteur 1: Pourcentage de r√©duction d'√©tapes (0-100%) - normalis√© 0-1
            step_reduction_pct = metrics.step_reduction_percentage()
            step_reduction_score = min(1.0, step_reduction_pct / 100.0)
            
            # Facteur 2: Nombre d'√©changes - normalis√© 0-1 (max 20 √©changes)
            exchanges_score = min(1.0, metrics.exchanges_count_raw() / 20.0)
            
            # Facteur 3: √âtapes duo - normalis√© 0-1 (moins = mieux, entre 50-500 √©tapes)
            min_steps, max_steps = 50, 500
            duo_steps = metrics.duo_steps_total()
            duo_steps_score = max(0.0, min(1.0, (max_steps - duo_steps) / (max_steps - min_steps)))
            
            # Score pond√©r√© final
            score = (
                step_reduction_score * weights.get('step_reduction_weight', 0.4) +  # 40% par d√©faut
                exchanges_score * weights.get('exchanges_weight', 0.4) +           # 40% par d√©faut  
                duo_steps_score * weights.get('duo_steps_weight', 0.2)             # 20% par d√©faut
            )
            
            total_score += score
        
        # Moyenne des scores par recette
        return total_score / len(self.metrics_by_recipe)
    
    def get_primary_recipe_group(self) -> int:
        """Retourne l'ID du groupe de recettes avec le meilleur score simplifi√©"""
        if not self.metrics_by_recipe:
            return 1
        
        # Trouver le groupe avec le meilleur pourcentage de r√©duction d'√©tapes
        best_group = max(self.metrics_by_recipe.items(), 
                        key=lambda x: x[1].step_reduction_percentage())
        return best_group[0]
    
    def average_step_reduction_percentage(self) -> float:
        """Pourcentage moyen de r√©duction d'√©tapes (m√©trique principale)"""
        if not self.metrics_by_recipe:
            return 0.0
        return sum(m.step_reduction_percentage() for m in self.metrics_by_recipe.values()) / len(self.metrics_by_recipe)
    
    def average_exchanges_count(self) -> float:
        """Nombre moyen d'√©changes (m√©trique principale)"""
        if not self.metrics_by_recipe:
            return 0.0
        return sum(m.exchanges_count_raw() for m in self.metrics_by_recipe.values()) / len(self.metrics_by_recipe)
    
    def average_duo_steps(self) -> float:
        """Nombre moyen d'√©tapes en mode duo (m√©trique principale)"""
        if not self.metrics_by_recipe:
            return float('inf')
        return sum(m.duo_steps_total() for m in self.metrics_by_recipe.values()) / len(self.metrics_by_recipe)

class LayoutDecompressor:
    """D√©compresse les layouts stock√©s"""
    
    def decode_grid_from_base64(self, encoded_grid: str) -> List[List[str]]:
        """D√©code une grille depuis base64"""
        grid_str = base64.b64decode(encoded_grid.encode('ascii')).decode('utf-8')
        lines = grid_str.strip().split('\n')
        return [list(line) for line in lines]
    
    def decompress_layout(self, compressed_layout: Dict) -> Dict:
        """D√©compresse un layout"""
        grid = self.decode_grid_from_base64(compressed_layout['g'])
        
        return {
            'grid': grid,
            'hash': compressed_layout['h'],
            'object_positions': compressed_layout.get('op', {})
        }

class LayoutSelector:
    """S√©lecteur principal de layouts"""
    
    def __init__(self, config_file: str = "config/pipeline_config.json"):
        """Initialise le s√©lecteur avec la configuration"""
        self.base_dir = Path(__file__).parent.parent
        self.config_file = self.base_dir / config_file
        self.config = self.load_config()
        
        # Configuration de s√©lection
        selection_config = self.config["pipeline_config"]["selection"]
        evaluation_config = self.config["pipeline_config"]["evaluation"]
        
        self.final_count = selection_config["final_count"]
        self.selection_method = selection_config["selection_method"]
        
        # Seuils de qualit√© simplifi√©s
        self.quality_thresholds = selection_config["quality_thresholds"]
        
        # Poids pour le calcul des scores - 3 m√©triques uniquement (valeurs par d√©faut)
        self.scoring_weights = {
            "step_reduction_percentage": 0.4,  # Importance de l'am√©lioration duo vs solo
            "exchanges_count": 0.3,            # Nombre d'√©changes d√©tect√©s
            "duo_steps_total": 0.3             # Efficacit√© totale en mode duo
        }
        
        # Override avec la config si elle existe
        if "scoring_weights" in selection_config:
            self.scoring_weights.update(selection_config["scoring_weights"])
        
        # R√©pertoires
        self.evaluation_dir = self.base_dir / "outputs" / evaluation_config["results_dir"]
        self.layouts_dir = self.base_dir / "outputs" / self.config["pipeline_config"]["output"]["layouts_generated_dir"]
        self.output_dir = self.base_dir / "outputs" / "layouts_finaux"
        
        # D√©compresseur
        self.decompressor = LayoutDecompressor()
        
        logger.info(f"üéØ S√©lecteur initialis√© - Target: {self.final_count} layouts")
        logger.info(f"üìÅ √âvaluations: {self.evaluation_dir}")
        logger.info(f"üìÅ Layouts: {self.layouts_dir}")
        logger.info(f"üíæ Sortie: {self.output_dir}")
    
    def load_config(self) -> Dict:
        """Charge la configuration du pipeline"""
        if not self.config_file.exists():
            raise FileNotFoundError(f"Configuration non trouv√©e: {self.config_file}")
        
        with open(self.config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def load_evaluation_results(self) -> Dict[str, LayoutMetrics]:
        """Charge tous les r√©sultats d'√©valuation"""
        logger.info("üìä Chargement des r√©sultats d'√©valuation...")
        
        metrics_files = list(self.evaluation_dir.glob("evaluation_metrics_batch_*.json"))
        
        if not metrics_files:
            raise FileNotFoundError(f"Aucun fichier de m√©triques trouv√© dans {self.evaluation_dir}")
        
        all_metrics = {}
        total_evaluations = 0
        
        for metrics_file in metrics_files:
            with open(metrics_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                for metric_data in data.get('metrics', []):
                    evaluation_id = metric_data['evaluation_id']
                    
                    metrics = LayoutMetrics(
                        layout_id=metric_data['layout_id'],
                        layout_hash=metric_data['layout_hash'],
                        recipe_group_id=metric_data['recipe_group_id'],
                        solo_steps=metric_data['solo_steps'],
                        duo_steps=metric_data['duo_steps'],
                        exchanges_count=metric_data['exchanges_count'],
                        recipe_hash=metric_data['recipe_hash']
                    )
                    
                    all_metrics[evaluation_id] = metrics
                    total_evaluations += 1
        
        logger.info(f"‚úÖ {total_evaluations} √©valuations charg√©es depuis {len(metrics_files)} fichiers")
        return all_metrics
    
    def load_layout_data(self) -> Dict[str, Dict]:
        """Charge les donn√©es des layouts depuis les fichiers compress√©s"""
        logger.info("üìÅ Chargement des donn√©es de layouts...")
        
        layout_files = list(self.layouts_dir.glob("layout_batch_*.jsonl.gz"))
        
        if not layout_files:
            raise FileNotFoundError(f"Aucun fichier de layout trouv√© dans {self.layouts_dir}")
        
        layout_data = {}
        
        for layout_file in layout_files:
            try:
                with gzip.open(layout_file, 'rt', encoding='utf-8') as f:
                    for line in f:
                        compressed_layout = json.loads(line.strip())
                        layout_hash = compressed_layout['h']
                        
                        # D√©compresser
                        decompressed = self.decompressor.decompress_layout(compressed_layout)
                        # Ajouter le hash original
                        decompressed['hash'] = layout_hash
                        layout_data[layout_hash] = decompressed
                        
            except Exception as e:
                logger.error(f"Erreur lors du chargement de {layout_file}: {e}")
        
        logger.info(f"‚úÖ {len(layout_data)} layouts charg√©s")
        return layout_data
    
    def group_metrics_by_layout(self, all_metrics: Dict[str, LayoutMetrics]) -> Dict[str, LayoutCandidate]:
        """Groupe les m√©triques par layout"""
        logger.info("üîÑ Groupement des m√©triques par layout...")
        
        layout_groups = defaultdict(lambda: defaultdict(list))
        
        # Grouper par layout_hash
        for evaluation_id, metrics in all_metrics.items():
            layout_groups[metrics.layout_hash][metrics.recipe_group_id].append(metrics)
        
        # Cr√©er les candidats
        candidates = {}
        layout_data = self.load_layout_data()
        
        for layout_hash, recipe_groups in layout_groups.items():
            if layout_hash not in layout_data:
                logger.warning(f"Donn√©es manquantes pour layout {layout_hash}")
                continue
            
            # Prendre la meilleure m√©trique par groupe de recettes
            metrics_by_recipe = {}
            for recipe_group_id, metrics_list in recipe_groups.items():
                # Prendre la m√©trique avec le meilleur pourcentage de r√©duction d'√©tapes
                best_metric = max(metrics_list, key=lambda m: m.step_reduction_percentage())
                metrics_by_recipe[recipe_group_id] = best_metric
            
            # Cr√©er le candidat
            layout = layout_data[layout_hash]
            candidate = LayoutCandidate(
                layout_id=layout_hash,
                layout_hash=layout_hash,
                grid=layout['grid'],
                object_positions=layout.get('object_positions', {}),
                metrics_by_recipe=metrics_by_recipe
            )
            
            candidates[layout_hash] = candidate
        
        logger.info(f"‚úÖ {len(candidates)} candidats cr√©√©s")
        return candidates
    
    def filter_candidates(self, candidates: Dict[str, LayoutCandidate]) -> Dict[str, LayoutCandidate]:
        """Filtre les candidats selon les seuils de qualit√©"""
        logger.info("üîç Filtrage des candidats selon les seuils de qualit√©...")
        
        filtered = {}
        debug_stats = {
            'step_reduction': [],
            'exchanges': [],
            'duo_steps': []
        }
        
        for layout_hash, candidate in candidates.items():
            # Calculer le score pond√©r√©
            score = candidate.calculate_weighted_score(self.scoring_weights)
            
            # V√©rifier les seuils simplifi√©s
            avg_step_reduction = candidate.average_step_reduction_percentage()
            avg_exchanges = candidate.average_exchanges_count()
            avg_duo_steps = candidate.average_duo_steps()
            
            # Collecter les stats pour debug
            debug_stats['step_reduction'].append(avg_step_reduction)
            debug_stats['exchanges'].append(avg_exchanges)
            debug_stats['duo_steps'].append(avg_duo_steps)
            
            if (avg_step_reduction >= self.quality_thresholds["min_step_reduction_percentage"] and
                avg_exchanges >= self.quality_thresholds["min_exchanges_count"] and
                avg_duo_steps <= self.quality_thresholds["max_duo_steps"]):
                
                filtered[layout_hash] = candidate
        
        # Logs de debug pour comprendre les valeurs
        if debug_stats['step_reduction']:
            step_red_stats = debug_stats['step_reduction']
            exch_stats = debug_stats['exchanges']
            duo_stats = debug_stats['duo_steps']
            
            logger.info(f"üìä STATS R√âDUCTION √âTAPES: min={min(step_red_stats):.1f}%, max={max(step_red_stats):.1f}%, moy={sum(step_red_stats)/len(step_red_stats):.1f}% (seuil: {self.quality_thresholds['min_step_reduction_percentage']}%)")
            logger.info(f"üìä STATS √âCHANGES: min={min(exch_stats):.1f}, max={max(exch_stats):.1f}, moy={sum(exch_stats)/len(exch_stats):.1f} (seuil: {self.quality_thresholds['min_exchanges_count']})")
            logger.info(f"üìä STATS √âTAPES DUO: min={min(duo_stats):.0f}, max={max(duo_stats):.0f}, moy={sum(duo_stats)/len(duo_stats):.0f} (seuil: {self.quality_thresholds['max_duo_steps']})")
        
        logger.info(f"‚úÖ {len(filtered)} candidats passent les filtres de qualit√©")
        return filtered
    
    def select_best_layouts(self, candidates: Dict[str, LayoutCandidate]) -> List[LayoutCandidate]:
        """S√©lectionne les meilleurs layouts selon la m√©thode configur√©e"""
        logger.info(f"üéØ S√©lection des {self.final_count} meilleurs layouts...")
        
        if self.selection_method == "best_per_recipe":
            return self._select_best_per_recipe(candidates)
        elif self.selection_method == "global_best":
            return self._select_global_best(candidates)
        else:
            logger.warning(f"M√©thode de s√©lection inconnue: {self.selection_method}, utilisation de 'global_best'")
            return self._select_global_best(candidates)
    
    def _select_global_best(self, candidates: Dict[str, LayoutCandidate]) -> List[LayoutCandidate]:
        """S√©lectionne les meilleurs layouts globalement selon les 3 m√©triques simplifi√©es"""
        
        # Calculer les scores avec tri prioritaire
        scored_candidates = []
        for candidate in candidates.values():
            score = candidate.calculate_weighted_score(self.scoring_weights)
            avg_exchanges = candidate.average_exchanges_count()
            avg_step_reduction = candidate.average_step_reduction_percentage()
            avg_duo_steps = candidate.average_duo_steps()
            
            # Crit√®re de tri multi-niveaux simplifi√© :
            # 1. Nombre d'√©changes moyens (priorit√© 1)
            # 2. R√©duction d'√©tapes en pourcentage (priorit√© 2)  
            # 3. Moins d'√©tapes duo = mieux (priorit√© 3, invers√©)
            # 4. Score global
            sort_key = (avg_exchanges, avg_step_reduction, -avg_duo_steps, score)
            scored_candidates.append((sort_key, candidate))
        
        # Trier par crit√®res prioritaires (d√©croissant sauf duo_steps)
        scored_candidates.sort(key=lambda x: x[0], reverse=True)
        
        # Log des meilleurs candidats pour debugging
        logger.info("üéØ TOP CANDIDATS (√©changes ‚Üí r√©duction% ‚Üí duo_steps) :")
        for i, (sort_key, candidate) in enumerate(scored_candidates[:min(5, len(scored_candidates))]):
            exchanges, reduction, neg_duo_steps, score = sort_key
            duo_steps = -neg_duo_steps
            logger.info(f"  #{i+1}: √âchanges={exchanges:.1f}, R√©duction={reduction:.1f}%, DuoSteps={duo_steps:.0f}, Score={score:.3f}")
        
        # Prendre les N meilleurs
        return [candidate for _, candidate in scored_candidates[:self.final_count]]
    
    def _select_best_per_recipe(self, candidates: Dict[str, LayoutCandidate]) -> List[LayoutCandidate]:
        """S√©lectionne les meilleurs layouts en essayant de couvrir diff√©rents groupes de recettes"""
        
        # Grouper par groupes de recettes couverts
        recipe_coverage = defaultdict(list)
        
        for candidate in candidates.values():
            recipe_groups = tuple(sorted(candidate.metrics_by_recipe.keys()))
            score = candidate.calculate_weighted_score(self.scoring_weights)
            recipe_coverage[recipe_groups].append((score, candidate))
        
        # S√©lectionner le meilleur de chaque groupe de recettes
        selected = []
        for recipe_groups, group_candidates in recipe_coverage.items():
            # Trier par score d√©croissant et prendre le meilleur
            group_candidates.sort(key=lambda x: x[0], reverse=True)
            selected.extend([candidate for _, candidate in group_candidates[:1]])
        
        # Si pas assez, compl√©ter avec les meilleurs globalement
        if len(selected) < self.final_count:
            all_candidates = list(candidates.values())
            scored_candidates = [(candidate.calculate_weighted_score(self.scoring_weights), candidate) 
                               for candidate in all_candidates]
            scored_candidates.sort(key=lambda x: x[0], reverse=True)
            
            selected_hashes = {c.layout_hash for c in selected}
            for _, candidate in scored_candidates:
                if len(selected) >= self.final_count:
                    break
                if candidate.layout_hash not in selected_hashes:
                    selected.append(candidate)
                    selected_hashes.add(candidate.layout_hash)
        
        return selected[:self.final_count]
    
    def convert_to_layout_format(self, candidate: LayoutCandidate, index: int) -> Dict:
        """Convertit un candidat au format .layout requis"""
        # Utiliser la grille du candidat
        grid = candidate.grid
        
        # Convertir la grille en string avec formatage sp√©cial
        grid_lines = []
        for row in grid:
            line = ''.join(row)
            grid_lines.append(line)
        
        # Formatage avec indentation comme dans l'exemple
        grid_str = '"""' + grid_lines[0] + '\n'
        for line in grid_lines[1:]:
            grid_str += '                ' + line + '\n'
        grid_str = grid_str.rstrip('\n') + '"""'
        
        # Recettes par d√©faut bas√©es sur la configuration
        start_all_orders = [
            {"ingredients": ["onion"]},
            {"ingredients": ["onion", "tomato"]}, 
            {"ingredients": ["tomato", "tomato"]},
            {"ingredients": ["onion", "onion", "tomato"]},
            {"ingredients": ["onion", "tomato", "tomato"]},
            {"ingredients": ["tomato", "tomato", "tomato"]}
        ]
        
        # Valeurs depuis la configuration
        recipe_config = self.config["pipeline_config"]["recipe_config"]
        base_values = recipe_config["base_values"]
        
        layout_dict = {
            "grid": grid_str,
            "start_all_orders": start_all_orders,
            "counter_goals": [],
            "onion_value": base_values["onion_value"],
            "tomato_value": base_values["tomato_value"],
            "onion_time": 9,
            "tomato_time": 6
        }
        
        return layout_dict
    
    def save_selected_layouts(self, selected_layouts: List[LayoutCandidate]):
        """Sauvegarde les layouts s√©lectionn√©s au format requis"""
        logger.info(f"üíæ Sauvegarde des {len(selected_layouts)} layouts s√©lectionn√©s...")
        
        # Cr√©er le r√©pertoire de sortie
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Sauvegarder chaque layout
        for i, candidate in enumerate(selected_layouts):
            # D√©terminer le groupe de recettes principal (celui avec le meilleur score)
            best_recipe_group = max(candidate.metrics_by_recipe.items(), 
                                  key=lambda x: x[1].step_reduction_percentage())[0]
            
            # Nom de fichier avec index, groupe de recettes et hash partiel
            filename = f"L{i+1:02d}_G{best_recipe_group:02d}_{candidate.layout_hash[:8]}.layout"
            filepath = self.output_dir / filename
            
            # Convertir au format requis
            layout_data = self.convert_to_layout_format(candidate, i)
            
            # G√©n√©rer le contenu du fichier avec le bon formatage
            content = "{\n"
            content += f'    "grid":  {layout_data["grid"]},\n'
            content += f'    "start_all_orders": {json.dumps(layout_data["start_all_orders"])},\n'
            content += f'    "counter_goals":{json.dumps(layout_data["counter_goals"])},\n'
            content += f'    "onion_value" : {layout_data["onion_value"]},\n'
            content += f'    "tomato_value" : {layout_data["tomato_value"]},\n'
            content += f'    "onion_time" : {layout_data["onion_time"]},\n'
            content += f'    "tomato_time" : {layout_data["tomato_time"]}\n'
            content += "}"
            
            # Sauvegarder
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # Calculer quelques statistiques pour le log
            score = candidate.calculate_weighted_score(self.scoring_weights)
            avg_step_reduction = candidate.average_step_reduction_percentage()
            avg_exchanges = candidate.average_exchanges_count()
            avg_duo_steps = candidate.average_duo_steps()
            
            logger.info(f"  ‚úÖ {filename}: score={score:.3f}, r√©duction={avg_step_reduction:.1f}%, √©changes={avg_exchanges:.1f}, steps={avg_duo_steps:.0f}")
        
        # Sauvegarder un r√©sum√© de la s√©lection
        summary = {
            "selection_timestamp": time.time(),
            "total_selected": len(selected_layouts),
            "selection_method": self.selection_method,
            "final_count_target": self.final_count,
            "quality_thresholds": self.quality_thresholds,
            "layouts": []
        }
        
        for i, candidate in enumerate(selected_layouts):
            layout_summary = {
                "index": i + 1,
                "filename": f"L{i+1:02d}_{candidate.layout_hash[:8]}.layout",
                "layout_hash": candidate.layout_hash,
                "weighted_score": candidate.calculate_weighted_score(self.scoring_weights),
                "step_reduction_percentage": candidate.average_step_reduction_percentage(),
                "exchanges_count": candidate.average_exchanges_count(),
                "duo_steps": candidate.average_duo_steps(),
                "recipe_groups_covered": len(candidate.metrics_by_recipe),
                "total_evaluations": len(candidate.metrics_by_recipe)
            }
            summary["layouts"].append(layout_summary)
        
        summary_file = self.output_dir / "selection_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìä R√©sum√© sauvegard√©: {summary_file}")
    
    def run_selection(self) -> bool:
        """Lance le processus de s√©lection complet"""
        start_time = time.time()
        
        try:
            # 1. Charger les r√©sultats d'√©valuation
            all_metrics = self.load_evaluation_results()
            
            # 2. Grouper par layout
            candidates = self.group_metrics_by_layout(all_metrics)
            
            # 3. Filtrer selon les crit√®res de qualit√©
            filtered_candidates = self.filter_candidates(candidates)
            
            if len(filtered_candidates) == 0:
                logger.error("‚ùå Aucun candidat ne passe les filtres de qualit√©")
                return False
            
            # 4. S√©lectionner les meilleurs
            selected_layouts = self.select_best_layouts(filtered_candidates)
            
            # 5. Sauvegarder
            self.save_selected_layouts(selected_layouts)
            
            selection_time = time.time() - start_time
            
            # Rapport final
            logger.info(f"‚úÖ S√©lection termin√©e en {selection_time:.1f}s")
            logger.info(f"üìä R√©sultats:")
            logger.info(f"   ‚Ä¢ {len(all_metrics)} √©valuations analys√©es")
            logger.info(f"   ‚Ä¢ {len(candidates)} layouts candidats")
            logger.info(f"   ‚Ä¢ {len(filtered_candidates)} candidats qualifi√©s")
            logger.info(f"   ‚Ä¢ {len(selected_layouts)} layouts finaux s√©lectionn√©s")
            logger.info(f"üíæ Layouts sauvegard√©s dans: {self.output_dir}")
            
            return True
            
        except Exception as e:
            logger.error(f"üí• Erreur lors de la s√©lection: {e}", exc_info=True)
            return False

def main():
    """Fonction principale"""
    parser = argparse.ArgumentParser(description="S√©lecteur de layouts Overcooked")
    parser.add_argument("--config", default="config/pipeline_config.json",
                       help="Fichier de configuration")
    parser.add_argument("--count", type=int,
                       help="Nombre de layouts √† s√©lectionner (override config)")
    
    args = parser.parse_args()
    
    try:
        selector = LayoutSelector(args.config)
        
        # Override du nombre si sp√©cifi√©
        if args.count:
            selector.final_count = args.count
            logger.info(f"üéØ Nombre overrid√©: {args.count} layouts")
        
        success = selector.run_selection()
        
        if success:
            logger.info("üéâ S√©lection r√©ussie!")
            return 0
        else:
            logger.error("‚ùå √âchec de la s√©lection")
            return 1
    
    except Exception as e:
        logger.error(f"üí• Erreur critique: {e}", exc_info=True)
        return 1

if __name__ == "__main__":
    import time
    exit(main())
