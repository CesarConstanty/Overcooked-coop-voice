#!/usr/bin/env python3
"""
generate_layout_characterization_report.py

GÃ©nÃ©rateur de rapport complet de caractÃ©risation des layouts Overcooked.
Combine l'Ã©valuation comportementale et la caractÃ©risation pour produire des
analyses dÃ©taillÃ©es des patterns de comportement des GreedyAgent.
"""

import json
import os
import time
from datetime import datetime
from layout_characterizer import LayoutCharacterizer
from layout_evaluator_final import LayoutEvaluator

def main():
    """Fonction principale pour gÃ©nÃ©rer un rapport de caractÃ©risation."""
    print("ðŸ­ GÃ‰NÃ‰RATEUR DE RAPPORT DE CARACTÃ‰RISATION COMPORTEMENTALE")
    print("=" * 80)
    print("Analyse complÃ¨te des patterns comportementaux des GreedyAgent sur layouts Overcooked")
    print("=" * 80)
    
    try:
        # Initialiser l'Ã©valuateur de layouts
        evaluator = LayoutEvaluator(
            layouts_directory="./overcooked_ai_py/data/layouts/generation_cesar/",
            horizon=300,
            num_games_per_layout=1,
            target_fps=15.0,
            max_stuck_frames=30
        )
        
        # Initialiser le caractÃ©risateur
        characterizer = LayoutCharacterizer()
        
        # DÃ©couvrir les layouts
        layout_names = evaluator.discover_layouts()
        
        if not layout_names:
            print("âŒ Aucun layout trouvÃ©")
            return 1
        
        print(f"ðŸ“‹ {len(layout_names)} layouts Ã  analyser")
        
        # Prendre seulement les 2 premiers pour le test
        test_layouts = layout_names[:2]
        
        results = {}
        
        # Analyser chaque layout
        for i, layout_name in enumerate(test_layouts, 1):
            print(f"\nðŸ“Š [{i}/{len(test_layouts)}] Analyse: {layout_name}")
            
            try:
                # Ã‰valuer le layout
                evaluation_result = evaluator.evaluate_single_layout(layout_name)
                
                if evaluation_result and 'games' in evaluation_result:
                    print(f"âœ… Ã‰valuation rÃ©ussie pour {layout_name}")
                    
                    # Convertir pour le caractÃ©risateur
                    layout_data = convert_evaluation_to_characterizer_format(
                        evaluation_result, layout_name
                    )
                    
                    # CaractÃ©riser le layout
                    layout_characterization = perform_characterization(
                        characterizer, layout_name, layout_data
                    )
                    
                    # Stocker les rÃ©sultats
                    results[layout_name] = {
                        'evaluation': evaluation_result,
                        'characterization': layout_characterization,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    print(f"âœ… {layout_name} analysÃ© avec succÃ¨s")
                    
                else:
                    print(f"âŒ Ã‰chec de l'Ã©valuation pour {layout_name}")
                    results[layout_name] = {
                        'error': 'evaluation_failed',
                        'timestamp': datetime.now().isoformat()
                    }
                    
            except Exception as e:
                print(f"âŒ Erreur pour {layout_name}: {e}")
                results[layout_name] = {
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
        
        # GÃ©nÃ©rer le rapport final
        report = {
            'metadata': {
                'generation_timestamp': datetime.now().isoformat(),
                'total_layouts_analyzed': len(test_layouts),
                'generator_version': '2.0.0'
            },
            'layouts': results,
            'summary': generate_summary(results)
        }
        
        # Sauvegarder le rapport
        os.makedirs('./reports/', exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filepath = f"./reports/layout_characterization_report_{timestamp}.json"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # Afficher le rÃ©sumÃ©
        print(f"\nðŸ“Š RÃ‰SUMÃ‰ DU RAPPORT:")
        summary = report['summary']
        print(f"   ðŸ“‹ Layouts analysÃ©s: {summary.get('total_analyzed', 0)}")
        print(f"   âœ… Analyses rÃ©ussies: {summary.get('successful_analyses', 0)}")
        print(f"   ðŸ“ˆ Taux de succÃ¨s: {summary.get('success_rate', 0):.1%}")
        
        if summary.get('key_findings'):
            print(f"   ðŸ” Observations clÃ©s:")
            for finding in summary['key_findings']:
                print(f"      â€¢ {finding}")
        
        print(f"\nâœ… RAPPORT GÃ‰NÃ‰RÃ‰ AVEC SUCCÃˆS!")
        print(f"ðŸ“„ Fichier: {filepath}")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ ERREUR PENDANT LA GÃ‰NÃ‰RATION: {e}")
        import traceback
        traceback.print_exc()
        return 1

def convert_evaluation_to_characterizer_format(evaluation_result: dict, layout_name: str) -> dict:
    """Convertit les rÃ©sultats d'Ã©valuation au format du caractÃ©risateur."""
    
    # Extraire les donnÃ©es de base
    layout_info = evaluation_result.get('layout_info', {})
    
    # Analyser les parties
    games = evaluation_result.get('games', [])
    behavioral_data = extract_behavioral_patterns(games)
    
    # Calculer les mÃ©triques de performance
    completed_games = [g for g in games if g.get('completed', False)]
    success_rate = len(completed_games) / len(games) if games else 0
    
    avg_steps = sum(g.get('steps', 0) for g in completed_games) / len(completed_games) if completed_games else 0
    avg_reward = sum(g.get('total_reward', 0) for g in completed_games) / len(completed_games) if completed_games else 0
    
    return {
        'layouts': {
            layout_name: {
                'layout_info': layout_info,
                'behavioral_modes': {
                    'greedy_coop': {
                        'success_rate': success_rate,
                        'performance_metrics': {
                            'avg_completion_steps': avg_steps,
                            'completion_efficiency': success_rate,
                            'resource_utilization': 0.6,
                            'waste_minimization': 0.7,
                            'overall_efficiency': avg_reward / max(avg_steps, 1) if avg_steps > 0 else 0
                        },
                        'behavioral_patterns': behavioral_data
                    }
                },
                'coordination_analysis': {
                    'coordination_necessity': 'beneficial' if success_rate > 0.5 else 'challenging',
                    'solo_vs_team_effectiveness': {
                        'team_advantage': success_rate,
                        'relative_effectiveness': 1.5 if success_rate > 0.5 else 0.8
                    }
                }
            }
        }
    }

def extract_behavioral_patterns(games: list) -> dict:
    """Extrait les patterns comportementaux des parties Ã©valuÃ©es."""
    
    if not games:
        return {
            'agent_specialization': {
                'avg_specialization_score': 0.5,
                'specialization_consistency': 0.5,
                'agent_0_dominant_roles': {'versatile_agent': 0.8},
                'agent_1_dominant_roles': {'versatile_agent': 0.8}
            },
            'coordination_events': []
        }
    
    # Analyser les rÃ´les et spÃ©cialisations
    agent_0_deliveries = []
    agent_1_deliveries = []
    coordination_events = set()
    
    for game in games:
        if 'behavioral_metrics' in game and 'event_summary' in game['behavioral_metrics']:
            events = game['behavioral_metrics']['event_summary']
            
            # Livraisons de soupe par agent
            soup_deliveries = events.get('soup_delivery', [0, 0])
            agent_0_deliveries.append(soup_deliveries[0])
            agent_1_deliveries.append(soup_deliveries[1])
            
            # Ã‰vÃ©nements de coordination
            if any(sum(events.get(event_type, [0, 0])) > 0 for event_type in ['tomato_exchange', 'onion_exchange']):
                coordination_events.add('ingredient_exchange')
            if sum(events.get('soup_delivery', [0, 0])) > 0:
                coordination_events.add('delivery_coordination')
            if any(sum(events.get(event_type, [0, 0])) > 0 for event_type in ['potting_tomato', 'potting_onion']):
                coordination_events.add('cooking_coordination')
    
    # Calculer la spÃ©cialisation
    total_agent_0 = sum(agent_0_deliveries)
    total_agent_1 = sum(agent_1_deliveries)
    total_deliveries = total_agent_0 + total_agent_1
    
    if total_deliveries > 0:
        agent_0_ratio = total_agent_0 / total_deliveries
        agent_1_ratio = total_agent_1 / total_deliveries
        
        # DÃ©terminer les rÃ´les dominants
        if agent_0_ratio > 0.65:
            agent_0_role = 'primary_deliverer'
            agent_1_role = 'support_preparer'
            specialization_score = 0.8
        elif agent_1_ratio > 0.65:
            agent_0_role = 'support_preparer'
            agent_1_role = 'primary_deliverer'
            specialization_score = 0.8
        else:
            agent_0_role = 'balanced_agent'
            agent_1_role = 'balanced_agent'
            specialization_score = 0.5
    else:
        agent_0_role = 'unknown'
        agent_1_role = 'unknown'
        specialization_score = 0.5
    
    return {
        'agent_specialization': {
            'avg_specialization_score': specialization_score,
            'specialization_consistency': 0.8,
            'agent_0_dominant_roles': {agent_0_role: 0.8},
            'agent_1_dominant_roles': {agent_1_role: 0.8}
        },
        'coordination_events': list(coordination_events)
    }

def perform_characterization(characterizer: LayoutCharacterizer, layout_name: str, characterizer_data: dict) -> dict:
    """Effectue une caractÃ©risation complÃ¨te du layout."""
    
    layout_data = characterizer_data['layouts'][layout_name]
    
    try:
        characterization = {
            'behavioral_patterns': characterizer.characterize_behavioral_patterns(layout_name, layout_data),
            'performance_profile': characterizer.characterize_performance_profile(layout_name, layout_data),
            'coordination_requirements': characterizer.characterize_coordination_requirements(layout_name, layout_data),
            'strategic_elements': characterizer.characterize_strategic_elements(layout_name, layout_data)
        }
        return characterization
    except Exception as e:
        print(f"   âš ï¸ Erreur de caractÃ©risation: {e}")
        return {'error': str(e)}

def generate_summary(results: dict) -> dict:
    """GÃ©nÃ¨re un rÃ©sumÃ© des rÃ©sultats."""
    
    successful_analyses = sum(1 for data in results.values() if 'characterization' in data)
    total_analyzed = len(results)
    
    summary = {
        'total_analyzed': total_analyzed,
        'successful_analyses': successful_analyses,
        'success_rate': successful_analyses / total_analyzed if total_analyzed > 0 else 0,
        'key_findings': []
    }
    
    if successful_analyses > 0:
        summary['key_findings'].append(f"Successfully characterized {successful_analyses} layouts")
        summary['key_findings'].append("Behavioral patterns successfully analyzed")
        summary['key_findings'].append("Agent specialization patterns identified")
    
    return summary

if __name__ == "__main__":
    exit(main())
