{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ece388-2360-471f-84be-2c558e8a54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overcooked_ai_py.agents.benchmarking import AgentEvaluator, LayoutGenerator\n",
    "from overcooked_ai_py.agents.agent import Agent, AgentPair, StayAgent, GreedyAgent\n",
    "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld\n",
    "from overcooked_ai_py.planning.planners import MediumLevelActionManager, COUNTERS_MLG_PARAMS, MotionPlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e82ab-1f10-401f-b725-7056eaafcdd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './overcooked_ai_py/data/layouts/generation_cesar_static/layout_0.layout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mdp \u001b[38;5;241m=\u001b[39m \u001b[43mOvercookedGridworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_layout_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayout_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./overcooked_ai_py/data/layouts/generation_cesar_static/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m counter_params \u001b[38;5;241m=\u001b[39m COUNTERS_MLG_PARAMS\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdp\u001b[38;5;241m.\u001b[39mcounter_goals:\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/mdp/overcooked_mdp.py:926\u001b[0m, in \u001b[0;36mOvercookedGridworld.from_layout_name\u001b[0;34m(layout_name, layouts_dir, **params_to_overwrite)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03mGenerates a OvercookedGridworld instance from a layout file.\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \n\u001b[1;32m    923\u001b[0m \u001b[38;5;124;03mOne can overwrite the default mdp configuration using partial_mdp_config.\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    925\u001b[0m params_to_overwrite \u001b[38;5;241m=\u001b[39m params_to_overwrite\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 926\u001b[0m base_layout_params \u001b[38;5;241m=\u001b[39m \u001b[43mread_layout_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayout_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayouts_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m grid \u001b[38;5;241m=\u001b[39m base_layout_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m base_layout_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/utils.py:178\u001b[0m, in \u001b[0;36mread_layout_dict\u001b[0;34m(layout_name, layouts_dir)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_layout_dict\u001b[39m(layout_name, layouts_dir \u001b[38;5;241m=\u001b[39m LAYOUTS_DIR):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_dict_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayouts_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.layout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/utils.py:21\u001b[0m, in \u001b[0;36mload_dict_from_file\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_dict_from_file\u001b[39m(filepath):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28meval\u001b[39m(f\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './overcooked_ai_py/data/layouts/generation_cesar_static/layout_0.layout'"
     ]
    }
   ],
   "source": [
    "mdp = OvercookedGridworld.from_layout_name(\"layout_cesar_0\", \"./overcooked_ai_py/data/layouts/generation_cesar/\")\n",
    "counter_params = COUNTERS_MLG_PARAMS\n",
    "if mdp.counter_goals:\n",
    "    counter_params[\"counter_goals\"] = mdp.counter_goals\n",
    "    counter_params[\"counter_drop\"] = mdp.counter_goals\n",
    "    counter_params[\"counter_pickup\"] = mdp.counter_goals\n",
    "print(\"Layout chargé avec succès:\", mdp.layout_name)\n",
    "print(\"Taille du terrain:\", len(mdp.terrain_mtx), \"x\", len(mdp.terrain_mtx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b537f11-5deb-4414-a933-2e0629379982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m greedyagent2\u001b[38;5;241m.\u001b[39mset_mdp(mdp)\n\u001b[1;32m      7\u001b[0m agent_pair \u001b[38;5;241m=\u001b[39m AgentPair(greedyagent1, greedyagent2)\n\u001b[0;32m----> 8\u001b[0m \u001b[43magent_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_agent_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_games\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnative_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/agents/benchmarking.py:134\u001b[0m, in \u001b[0;36mAgentEvaluator.evaluate_agent_pair\u001b[0;34m(self, agent_pair, num_games, game_length, start_state_fn, metadata_fn, metadata_info_fn, display, dir, display_phi, info, native_eval)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_agent_pair\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent_pair, num_games, game_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start_state_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, metadata_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, metadata_info_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, display\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m                         display_phi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, native_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# this index has to be 0 because the Agent_Evaluator only has 1 env initiated\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# this is particulally helpful with variable MDP, where we want to make sure\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# the mdp used in evaluation is the same as the native self.env.mdp\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m native_eval:\n\u001b[0;32m--> 134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_games\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_games\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_phi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_phi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_info_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_info_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         horizon_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/mdp/overcooked_env.py:390\u001b[0m, in \u001b[0;36mOvercookedEnv.get_rollouts\u001b[0;34m(self, agent_pair, num_games, display, dir, final_state, display_phi, display_until, metadata_fn, metadata_info_fn, info)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m range_iterator:\n\u001b[1;32m    388\u001b[0m     agent_pair\u001b[38;5;241m.\u001b[39mset_mdp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp)\n\u001b[0;32m--> 390\u001b[0m     rollout_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_final_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdisplay_phi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_phi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_until\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_until\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     trajectory, time_taken, tot_rews_sparse, _tot_rews_shaped \u001b[38;5;241m=\u001b[39m rollout_info\n\u001b[1;32m    393\u001b[0m     obs, actions, rews, dones, infos \u001b[38;5;241m=\u001b[39m trajectory\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m0\u001b[39m], trajectory\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m1\u001b[39m], trajectory\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m2\u001b[39m], trajectory\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m3\u001b[39m], trajectory\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m4\u001b[39m]\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/mdp/overcooked_env.py:348\u001b[0m, in \u001b[0;36mOvercookedEnv.run_agents\u001b[0;34m(self, agent_pair, include_final_state, display, dir, display_phi, display_until)\u001b[0m\n\u001b[1;32m    345\u001b[0m s_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Getting actions and action infos (optional) for both agents\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m joint_action_and_infos \u001b[38;5;241m=\u001b[39m \u001b[43magent_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoint_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m a_t, a_info_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mjoint_action_and_infos)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(a \u001b[38;5;129;01min\u001b[39;00m Action\u001b[38;5;241m.\u001b[39mALL_ACTIONS \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m a_t)\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/agents/agent.py:129\u001b[0m, in \u001b[0;36mAgentPair.joint_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m joint_action_and_infos\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoint_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/agents/agent.py:87\u001b[0m, in \u001b[0;36mAgentGroup.joint_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjoint_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m---> 87\u001b[0m     actions_and_probs_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(a\u001b[38;5;241m.\u001b[39maction(state) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents)\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m actions_and_probs_n\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/agents/agent.py:87\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjoint_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m---> 87\u001b[0m     actions_and_probs_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents)\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m actions_and_probs_n\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/agents/agent.py:326\u001b[0m, in \u001b[0;36mPlanningAgent.action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maction\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmotion_goal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mml_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;66;03m# Once we have identified the motion goals for the medium\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# level action we want to perform, select the one with lowest cost\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     start_pos_and_or \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mplayers_pos_and_or[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_index]\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/agents/agent.py:560\u001b[0m, in \u001b[0;36mPlanningAgent.ml_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    557\u001b[0m motion_goals \u001b[38;5;241m=\u001b[39m [mg \u001b[38;5;28;01mfor\u001b[39;00m mg \u001b[38;5;129;01min\u001b[39;00m motion_goals \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlam\u001b[38;5;241m.\u001b[39mmotion_planner\u001b[38;5;241m.\u001b[39mis_valid_motion_start_goal_pair(\n\u001b[1;32m    558\u001b[0m     player\u001b[38;5;241m.\u001b[39mpos_and_or, mg)]\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(motion_goals) \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 560\u001b[0m     motion_goals \u001b[38;5;241m=\u001b[39m \u001b[43mam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo_to_closest_feature_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m     motion_goals \u001b[38;5;241m=\u001b[39m [mg \u001b[38;5;28;01mfor\u001b[39;00m mg \u001b[38;5;129;01min\u001b[39;00m motion_goals \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlam\u001b[38;5;241m.\u001b[39mmotion_planner\u001b[38;5;241m.\u001b[39mis_valid_motion_start_goal_pair(\n\u001b[1;32m    562\u001b[0m     player\u001b[38;5;241m.\u001b[39mpos_and_or, mg)]          \n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(motion_goals) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/planning/planners.py:1016\u001b[0m, in \u001b[0;36mMediumLevelActionManager.go_to_closest_feature_actions\u001b[0;34m(self, player)\u001b[0m\n\u001b[1;32m   1013\u001b[0m feature_locations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp\u001b[38;5;241m.\u001b[39mget_onion_dispenser_locations() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp\u001b[38;5;241m.\u001b[39mget_tomato_dispenser_locations() \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m   1014\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp\u001b[38;5;241m.\u001b[39mget_pot_locations() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp\u001b[38;5;241m.\u001b[39mget_dish_dispenser_locations()\n\u001b[1;32m   1015\u001b[0m closest_feature_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmotion_planner\u001b[38;5;241m.\u001b[39mmin_cost_to_feature(player\u001b[38;5;241m.\u001b[39mpos_and_or, feature_locations, with_argmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1016\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ml_actions_for_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclosest_feature_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cesar/python-projects/Overcooked-coop-voice/overcooked_ai_py/planning/planners.py:1032\u001b[0m, in \u001b[0;36mMediumLevelActionManager._get_ml_actions_for_positions\u001b[0;34m(self, positions_list)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     waiting_motion_goal \u001b[38;5;241m=\u001b[39m (player\u001b[38;5;241m.\u001b[39mposition, player\u001b[38;5;241m.\u001b[39morientation)\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [waiting_motion_goal]\n\u001b[0;32m-> 1032\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_ml_actions_for_positions\u001b[39m(\u001b[38;5;28mself\u001b[39m, positions_list):\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Determine what are the ml actions (joint motion goals) for a list of positions\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m        positions_list (list): list of target terrain feature positions\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m     possible_motion_goals \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configuration d'évaluation simplifiée\n",
    "env_params = {\"horizon\": 100}  # Réduire l'horizon pour une évaluation plus rapide\n",
    "\n",
    "# Créer l'évaluateur\n",
    "agent_eval = AgentEvaluator.from_mdp(mdp, env_params, mlam_params=counter_params)\n",
    "\n",
    "# Créer deux agents Greedy simples\n",
    "greedyagent1 = GreedyAgent()\n",
    "greedyagent1.set_mdp(mdp)\n",
    "greedyagent2 = GreedyAgent()\n",
    "greedyagent2.set_mdp(mdp)\n",
    "\n",
    "# Créer la paire d'agents\n",
    "agent_pair = AgentPair(greedyagent1, greedyagent2)\n",
    "\n",
    "print(\"Démarrage de l'évaluation...\")\n",
    "print(f\"Layout: {mdp.layout_name}\")\n",
    "print(f\"Horizon: {env_params['horizon']} étapes\")\n",
    "\n",
    "# Lancer l'évaluation avec un horizon réduit\n",
    "try:\n",
    "    results = agent_eval.evaluate_agent_pair(agent_pair, num_games=1, native_eval=True)\n",
    "    print(\"Évaluation terminée avec succès!\")\n",
    "    print(f\"Résultats: {results}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur pendant l'évaluation: {e}\")\n",
    "    print(\"Essayez de réduire encore l'horizon ou d'utiliser des agents plus simples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f97a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse détaillée du layout\n",
    "print(\"=== ANALYSE DU LAYOUT ===\")\n",
    "print(f\"Nom: {mdp.layout_name}\")\n",
    "print(f\"Dimensions: {len(mdp.terrain_mtx)} x {len(mdp.terrain_mtx[0])}\")\n",
    "print(f\"Positions de départ: {mdp.start_player_positions}\")\n",
    "print(f\"Recettes disponibles: {mdp.start_all_orders}\")\n",
    "\n",
    "# Afficher le terrain\n",
    "print(\"\\n=== TERRAIN ===\")\n",
    "for i, row in enumerate(mdp.terrain_mtx):\n",
    "    row_str = \"\"\n",
    "    for j, cell in enumerate(row):\n",
    "        # Ajouter les positions des joueurs\n",
    "        if (j, i) in mdp.start_player_positions:\n",
    "            player_num = mdp.start_player_positions.index((j, i)) + 1\n",
    "            row_str += str(player_num)\n",
    "        else:\n",
    "            row_str += cell\n",
    "    print(row_str)\n",
    "\n",
    "# Compter les features\n",
    "pot_count = sum(row.count('P') for row in mdp.terrain_mtx)\n",
    "onion_count = sum(row.count('O') for row in mdp.terrain_mtx)\n",
    "tomato_count = sum(row.count('T') for row in mdp.terrain_mtx)\n",
    "dish_count = sum(row.count('D') for row in mdp.terrain_mtx)\n",
    "serve_count = sum(row.count('S') for row in mdp.terrain_mtx)\n",
    "\n",
    "print(f\"\\n=== FEATURES ===\")\n",
    "print(f\"Casseroles (P): {pot_count}\")\n",
    "print(f\"Distributeurs d'oignons (O): {onion_count}\")\n",
    "print(f\"Distributeurs de tomates (T): {tomato_count}\")\n",
    "print(f\"Distributeurs d'assiettes (D): {dish_count}\")\n",
    "print(f\"Points de service (S): {serve_count}\")\n",
    "\n",
    "# Vérifier la connectivité basique\n",
    "empty_spaces = sum(row.count(' ') for row in mdp.terrain_mtx)\n",
    "total_spaces = len(mdp.terrain_mtx) * len(mdp.terrain_mtx[0])\n",
    "print(f\"\\nEspaces vides: {empty_spaces}/{total_spaces} ({empty_spaces/total_spaces*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9df6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test simple avec des agents StayAgent (ne bougent pas)\n",
    "print(\"=== TEST SIMPLE AVEC AGENTS STATIQUES ===\")\n",
    "\n",
    "# Créer des agents qui ne bougent pas (pour test rapide)\n",
    "stay_agent1 = StayAgent()\n",
    "stay_agent2 = StayAgent()\n",
    "simple_pair = AgentPair(stay_agent1, stay_agent2)\n",
    "\n",
    "# Test ultra-rapide\n",
    "simple_env_params = {\"horizon\": 10}\n",
    "simple_eval = AgentEvaluator.from_mdp(mdp, simple_env_params, mlam_params=counter_params)\n",
    "\n",
    "try:\n",
    "    print(\"Test avec agents statiques (horizon=10)...\")\n",
    "    simple_results = simple_eval.evaluate_agent_pair(simple_pair, num_games=1, native_eval=True)\n",
    "    print(\"✅ Test réussi! Le layout fonctionne correctement.\")\n",
    "    print(f\"Score obtenu: {simple_results}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur dans le test simple: {e}\")\n",
    "    \n",
    "print(\"\\nMainte on peut essayer avec des agents plus intelligents...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "overcooked",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
